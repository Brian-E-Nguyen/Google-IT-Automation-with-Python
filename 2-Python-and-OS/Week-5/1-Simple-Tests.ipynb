{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Tests\n",
    "\n",
    "In this module, we'll dive into how we can create automatic test that will perform these kinds of checks for us. This lets us concentrate on just writing the code instead of checking if any changes that we make to it break the previous functionality. It will also help us verify that features we add do what we expect in lots of possible ways. We'll learn about the different kinds of testing that are out there, and how we can use them to make our code more reliable, and finally, we'll also learn about how to handle errors and exceptions in Python code. How to trap those areas so they don't stop our programs from completing, how to raise errors when necessary, and how to test our code to generate the right kinds of errors. That sounds interesting. Now let's get to it.\n",
    "\n",
    "## 1. What is Testing?\n",
    "\n",
    "When you're writing a very simple piece of code, say for example, that you're adding two variables, it's pretty straightforward to know what the code does, and be sure they'd does it correctly. As operations become more complex using loops, conditionals, calling more and more functions, it's harder to really be confident that the code will do what it's supposed to. This is where software testing comes into play. \n",
    "\n",
    "**Software testing** is a process of evaluating computer code to determine whether or not it does what you expect it to do. When you test a piece of software, you want to find the errors and defects and see where things go wrong. Software testing is similar in lots of ways to the tests performed in the manufacturing process of a new piece of machinery. \n",
    "\n",
    "When a new car comes off the line, you want to make sure that when you press the gas the car will go, and when you press the brakes the car will stop. It's the same idea with software. You want to make sure that when you run a program, it behaves the way that it should, then you can really put the pedal to the metal. Vroom, vroom. \n",
    "\n",
    "Scripts and programs can fail in all sorts of strange ways, especially as it become more complicated. In all but those simple programs, it's next to impossible to test for everything that could go wrong. Even though this means that a certain number of bugs might exist in your scripts without you realizing it, don't worry. Writing tests can help you eliminate a whole bunch of bugs, helping to improve the reliability and the quality of automation. \n",
    "\n",
    "Tests can help make good code great. The field of software testing is pretty broad. In the next few videos we'll explore some fundamental concepts involved like **automated testing, unit test, integration test, and test-driven development**. As of lots of topics covered in this course, we'll do a quick rundown of the many concepts around testing. It won't be enough instructions for you to become a testing expert, but it should help you with automatically testing your scripts. Up next, we'll talk about the differences between manual and automated testing, so let's shift gears and get started.\n",
    "\n",
    "## 2. Manual Testing and Automated Testing\n",
    "\n",
    "One of the tasks that programmers had to do when writing code is test it to make sure that it behaves the way that they expected to. Having good tests for our software can help us catch mistakes, errors, and bugs before we deploy our scripts to perform real-world automation tasks. The most basic way of testing a script is to run it with different parameters and see if it returns the expected values. We've done this manual testing for some of the code that we've written this course already. \n",
    "Executing a script with different command-line arguments to see how its behavior changed is an example of manual testing. Using the interpreter to try our code before putting it in a script is another form of manual testing. \n",
    "\n",
    "Formal software testing takes us process a step further, codifying tests into its own software and code that can be run to verify that our programs do what we expect them to do. This is called **automatic testing**. The goal of automatic testing is to automate the process of checking if the returned value matches the expectations. Instead of us humans running a function over and over with different parameters and checking the results are what we expected them to be, we let the computer do this for us. \n",
    "\n",
    "Automatic testing means we'll write code to do the test. Why would you write more code to test code you have? Because when you're testing your code, you want to check if it does what it's supposed to do for a lot of different values. You ought to verify that it behaves the way you expect it to have as many possible values known as **test cases**. \n",
    "\n",
    "Say you're writing a script that updates a list of email addresses to use a new domain, similar to the one we wrote a while back. You'll want to test what happens when your list of emails has one element, two elements, or 10 elements. You want to test what happens if the new domain is one character long, or 20 characters long, or even an empty string. You'll also want to test what happens if the list contains only emails that need to be updated, only emails that don't need to be updated, or a mix of them. As you can see the list of things that you want to test for can get very long, very fast. The more test cases that you include in your test, the better tested your code is and the more you can guarantee that your code does what you expect it to do. \n",
    "\n",
    "If we're testing this manually, it's unlikely that we'll go through all the cases whenever we change our code. We'll test just a few, possibly, letting a bug slipped through. Not ideal. This is why we don't want to perform these tests manually and instead, want to make a computer do it for us. \n",
    "\n",
    "Just like with any example of automation, the advantage of automatic tests is that we can run them as many times as necessary and will always get the same results. The computer will do the same checks over and over and we'll always make sure that the return value matches our expectation. When for some reason the results don't match the expectations, the code will raise an error, so we can check the code and find out what's going on. There's a bunch of different types of tests that we can write to perform automatic testing.\n",
    "\n",
    "## 3. Unit Tests\n",
    "\n",
    "As we mentioned, there are lots of different types of test that we can write to perform automatic testing. The most common type is a unit test. **Unit tests** are used to verify that small isolated parts of a program are correct. Unit tests are generally written alongside the code to test the behavior of individual pieces or units like functions or methods. \n",
    "\n",
    "Unit tests help assure the developer that each piece of code does what it's meant to do. An important characteristic of a unit test is **isolation**. Unit test should only test the unit of code they target, the function or method that's being tested. This ensures that any success or failure of the test is caused by the behavior of the unit in question and doesn't result from some external factor like the network being down or a database server being unresponsive. In other words, when testing a function or method, we want to make sure that we're focusing on checking that the code in that function or method behaves correctly. We don't want our test to fail for external reasons. \n",
    "\n",
    "On a related note, our tests should never modify the production environment. This is a live environment that runs a software that users interact with. When developing test, if for any reason we do need to interact with some other software, we'll normally do that in a **test environment**, where we'll have control over how it behaves. It's our house, our rules. So the goal of the unit test is to verify that small, isolated parts of a program are correct. \n",
    "\n",
    "How do we do that? It generally boils down to a simple pattern. Given a known input, does the output of our code match our expectations? Let's take a piece of code similar to what we wrote awhile back to rearrange a name in the format last name comma first name and think about how we test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: from rearrange.py\n",
    "import re\n",
    "\n",
    "def rearrange_name(name):\n",
    "    result = re.search(r'^([\\w .]*), ([\\w .]*)$', name)\n",
    "    return '{} {}'.format(result[2], result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you think we can test that it works the way you'd expect it to? Let's start by manually validating that for a given input, it produces expected result. We'll check this by importing the function in an interpreter. To do that, we'll use a keyword that we haven't seen before,`from`, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rearrange import rearrange_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, rearrange is the name of the module that contains the rearrange_name function. By importing it in this way, we can call the function without having to write the module name each time we want to call it, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jack Evans'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange_name('Evans, Jack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function has produced the output we expected, given the input we provided. So it has pass this particular unit test. Gold star, hang it on a fridge. The test focus on a small isolated piece of the code and validated our assumption about how it worked. Because the scope of the test is restricted to a small specific unit, these types of tests usually run pretty quickly. Debugging them is simple since there are a limited number of reasons for them to fail. Creating unit tests for our code will mean writing a bunch of test cases that verify that when we input some parameters, we get the output that we want. Of course, the whole point is to run these tests automatically so that we don't have to manually do this ourselves each time. Up next, we'll talk about how we can actually write automatic tests in Python. Exciting, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
