{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Computer Resources\n",
    "\n",
    "## 1. Intro to Module 4: Managing Resources\n",
    "\n",
    "Welcome back. We're almost to the end of the course. Congratulations on making it all the way here. I hope you're starting to see just how practical these lessons are in a real-world IT environment, and that you're feeling empowered by your new troubleshooting skills. In past modules, you've learned how to troubleshoot and debug a bunch of situations. We saw how reducing scope and isolating problems can lead us to the root cause of programs that are running slowly or crushing unexpectedly. We also learned how to understand different error messages and use the tools available in the OS to diagnose what's going on. \n",
    "\n",
    "Sometimes the problem we face isn't that something doesn't work, but that it doesn't work as well as it should. Usually, this comes down to not making the best use of the available resources in the system. If our program uses too much memory for example, we might be able to work around it by adding more RAM to the computer. But wouldn't it be better if it didn't use that much memory in the first place? \n",
    "\n",
    "All resources in our computer are limited. So we need to make sure that the applications we run make the best use of them. We need to check that the software we run doesn't waste memory for things that aren't needed, or that the space on our disks is actually used by data that matters, or that the information transmitted over the network is actually the info we care about. There's always something to declutter. \n",
    "\n",
    "In the next few videos, we'll explore how we can figure out what's going on with programs that exhaust resources on our computer. Whether that's memory, disk, or even network link. Then will talk about managing our most valuable resource of all, time. We'll learn how we can look at the never-ending list of tasks that needs to be done, and make sure that we're spending our time wisely by prioritizing our work and avoiding unnecessary interruptions. After that, we'll discuss how we can apply all our new knowledge to try to avoid future problems. Being proactive could help us mitigate issues when things don't go according to plan. Hint, they rarely do, and even if would problems altogether by catching them in the test infrastructure. Finally, you'll have another opportunity to try your hand at solving a real world challenge, to put your skills into practice. Ready to get started? All right. Let's do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Memory Leaks and How to Prevent Them\n",
    "\n",
    "Most applications need to store data in memory to run successfully. We called that earlier, how processes interact with the OS to request chunks of memory, and then release them when they're no longer needed. \n",
    "\n",
    "When writing programs in languages like C, or C plus plus, the programmer is in charge of deciding how much memory to request, and when to give it back. Since we're human, we might sometimes forget to free memory that isn't in use anymore, this is what we call a Memory leak. A **memory leak,** *happens when a chunk of memory that's no longer needed is not released.* If the memory leak is small, we might not even notice it, and it probably won't cause any problems. But, when the memory that's leaked becomes larger and larger over time, it can cause the whole system to start misbehaving, not cool memory leak, not cool. \n",
    "\n",
    "When a program uses a lot of RAM, other programs will need to be swapped out and everything will run slowly. If the program uses all of the available memory, then no processes will be able to request more memory, and things will start failing in weird ways. When this happens, the OS might terminate processes to free up some of the memory, causing unrelated programs to crash. \n",
    "\n",
    "You might be thinking why should I care if I don't plan to code in C or C plus plus, it's true, the languages like Python, Java, or Go manage memory for us, but things can still go wrong if we don't use the memory correctly. To understand how this works, let's look into what these languages do. First, they request the necessary memory when we create variables, and then they run a tool called **Garbage collector,** *that's in charge of freeing the memory that's no longer in use.* To detect when that's the case, the garbage collector looks at the variables in use and the memory assigned to them and then checks if there any portions of the memory that aren't being referenced by any variables. \n",
    "\n",
    "Say for example, you create a dictionary inside a function, use it to process a text file, calculate the frequency of the words in the file, and then return the word that was used the most frequently. When the function returns, the dictionary is not referenced anymore. So the garbage collector can detect this and give back the unused memory, but if the function returns the whole dictionary, then it's still in use, and the memory won't be given back until that stops being the case. \n",
    "\n",
    "When our code keeps variables pointing to the data in memory, like a variable in the code itself, or an element in a list or a dictionary, the garbage collector won't release that memory. In other words, even when the language takes care of requesting and releasing the memory for us, we could still see the same effects of a memory leak. If that memory keeps growing, the code could cause the computer to run out of memory, just like a memory leak would. The OS will normally released any memory assigned to a process once the process finishes. So memory leaks are less of an issue for programs that are short lived, but can become especially problematic for processes that keep running in the background. Even worse than these, are memory leaks caused by a device driver, or the OS itself. In these cases, only a full restart of the system releases the memory.\n",
    "\n",
    "Say you notice that your computer seems to run out of memory a lot, you look at the running programs over the course of some time, and realize that there's a process that keeps using more and more memory as the hours pass. If you reset that process, it begins with a very small amount of memory, but quickly requires more and more. If that's the case, it's pretty likely that this program has a memory leak. So let's jog its memory, what can we do if we suspect a program has a memory leak? We can use a memory profiler to figure out how the memory is being used. \n",
    "\n",
    "As what debuggers will have to use the right profiler for the language of the application. For profiling C and C plus plus programs, we'll use **Valgrind** which we mentioned in an earlier video. For profiling a Python, there are bunch of different tools that are disposal, depending on what exactly we want to profile. We can be as detailed as profiling the memory usage of a single function, or as big picture as monitoring the total memory consumption over time. Using profilers, we can see what structures are using the most memory at one in time or take snapshots at different points in time and compare them. The goal of these tools is to help us identify which information we're keeping in memory that we don't actually need. \n",
    "\n",
    "It's important that we measure the use of memory first before we try to change anything, otherwise we might be optimizing the wrong piece of code. Sometimes we need to keep data in memory, and that's fine, but you want to make sure that you're only keeping the data that you actually need, and that you've let go of anything you won't be using, that way the garbage collector can give that memory back to the OS. Of course, if you check that you're using the memory correctly, but still find that your exhausting available RAM, it might be time for an upgrade. \n",
    "\n",
    "Did you commit all that to memory? Don't forget, there's a lot more to say about memory profiling than we have time to cover it, but we've included links to more information about some of these profiling tools in the next reading. Up next, we'll talk about a different resource that might need some special care, disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Managing Disk Space\n",
    "\n",
    "Another resource that might need our attention is the disk usage of our computer. Programs may need disk space for lots of different reasons. \n",
    "\n",
    "- Installed binaries and libraries, \n",
    "- data stored by the applications, \n",
    "- cached information, \n",
    "- logs, \n",
    "- temporary files \n",
    "- or even backups. \n",
    "\n",
    "If our computers running out of space, it's possible that we're trying to store too much data in too little space. Maybe we have too many applications installed, or we're trying to store too many large files in the drive. But it's also possible that programs are misusing the space allotted to them, like by keeping temporary files or caching information that doesn't get cleaned up quickly enough or at all. It's common for the overall performance of the system to decrease as the available disk space gets smaller. Data starts getting fragmented across the desk, and operations become slower. When a hard drive is full, programs may suddenly crash, while trying to write something into disk and finding out that they can't. \n",
    "\n",
    "A full hard drive might even lead to data loss, as some programs might truncate a file before writing an updated version of it, and then fail to write the new content, losing all the data that was stored in it before. Yikes. If it gets to this point, we'll probably see some error, like **no space left on device** when running our applications or in the logs. \n",
    "\n",
    "So what do you do if a computer runs out of disk space? If it's a user machine, it might be easily fixed by uninstalling applications that aren't used, or cleaning up old data that isn't needed anymore. But if it's a server, you might need to look more closely at what's going on. Is the issue that you need to add an extra drive to the server to have more available space, or is it that some application is misbehaving and filling the disk with useless data? \n",
    "\n",
    "To figure this out, you want to look at how the space is being used and what directories are taking up the most space, then drill down until you find out whether large chunks of space are taken by valid information or by files that should be perched. For example, on a database server, it's expected that the bulk of the disc space is going to be used by the data stored in the database. A mail server, it's going to be the mailboxes of the users of that service. But if you find that most of the data is stored in logs or in temporary files, something has gone wrong. \n",
    "\n",
    "One common pattern of misbehavior is a program that keeps logging error messages to the system log over and over. This can happen for lots of different reasons. For example, the OS might keep trying to start a program that fails because of a configuration problem. This will generate a new log entry with every retry, and can take up a lot of space if there are several retries per second, or it could be that the server has a lot of activity and the logs are real. But there are just too many of them. In that case, you might want to look on the tweaking, the configuration of the tools that rotate the logs more frequently, to make sure that you're keeping only what you need. \n",
    "\n",
    "In other cases, the disk might get full due to a program generating large temporary files, and then failing to clean those up. For example, an application might clean up temporary files when shutting down cleanly, but leave them behind if it crashes. Or it could simply be a programming error of creating temporary files and never cleaning them up. In a case like this, you'll ideally have some housekeeping to fix the program, and delete those files correctly. But if that's not possible, you might need to write your own script that gets rid of them. \n",
    "\n",
    "A situation that might be tricky to debug is when the files taking up the space or deleted files. I'm sure you're wondering, how can deleted files take up space? Great question. Well, if a program opens a file, the OS lets that program read and write in the file regardless of whether the file is marked as deleted or not. So lots of programs delete the temporary files they create right after opening to avoid issues with failing to clean them up later. That way, the process can read from and write to the file while the file is open. Then when the process finishes, the file gets closed and actually deleted. Now, this system is widely used and works fine for most processes. But if for some reason, this temporarily deleted file starts becoming super large, it can end up taking up all the available disk space. If that happens, we'll be left scratching our heads when trying to figure out where most of the data went, since we won't see these deleted files. To check for the specific condition, we need to list the currently opened files, and comb for the ones that we know are deleted. We include pointers to the commands for how that works in the next reading. \n",
    "\n",
    "Of course, there are all kinds of other reasons why the disk may be getting too full. Just remember that whenever this happens, your process will remain the same. You'll need to spend some time looking into what's using the disk. Check to see if it's expected or an anomaly, figure out how to solve it, and most important of all, how to prevent it from happening again? Up next, we'll discuss yet another resource that might cause some trouble. The network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Network Saturation\n",
    "\n",
    "When you work in IT, you interact with services all over the Internet. At one moment, you might connect to a service running on your local network and the next use another service running in a data center located on a different continent. If your network connection is good, you might not be able to tell the difference where the website you're browsing is hosted. But if you're dealing with a network service that isn't exactly up to speed, you might need to get more details about the connection you're using. \n",
    "\n",
    "The two most important factors that determine the time it takes to get the data over the network are the latency and the bandwidth of the connection. The **latency** *is the delay between sending a byte of data from one point and receiving it on the other.* This value is directly affected by the physical distance between the two points and how many intermediate devices there are between them. The **bandwidth** *is how much data can be sent or received in a second.* This is effectively the data capacity of the connection. Internet connections are usually sold by the amount of bandwidth the customer will see. But it's important to know that the usable bandwidth to transmit data to and from a network service will be determined by the available bandwidth at each endpoint and every hop between them. \n",
    "\n",
    "To understand how latency and bandwidth interact, think about what happens when you try to visit a website over the Internet. If the web server is hosted somewhere across the ocean, the latency might be a 100 milliseconds or so. That's the time it takes for your request to reach the server. The server will then generate a response and send it back to you. The first bytes of the response will again take a 100 milliseconds to zap across the pond to your computer. Once the response is on its way, the time it takes for the rest of the data to arrive is determined by the bandwidth. If the available bandwidth between the two points is 10 megabits per second, you'll be able to receive 1.25 megabytes every second. So for a website of about one megabyte of content, that large initial latency will be noticeable, since it's an extra 20 percent on top of the total time to download it. But if the content is 10 megabytes or more, the initial latency will be less than five percent of the total time to download it. So it matters less. \n",
    "\n",
    "![img1](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img1.jpg?raw=true)\n",
    "\n",
    "Let's say you're trying to figure out why a network connection isn't going as fast as you want. Remember that if you're transmitting a lot of small pieces of data, you care more about latency than bandwidth. In this case, you want to make sure that the server is as close as possible to the users of the service, aiming for a latency of less than 50 milliseconds if possible, and up to a 100 milliseconds in the worst-case.\n",
    "\n",
    "![img2](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img2.jpg?raw=true)\n",
    "\n",
    "On the flip side, if you're transmitting large chunks of data, you care more about the bandwidth than the latency. In this case, you want to have as much bandwidth available as possible regardless of where the server is hosted. \n",
    "\n",
    "![img3](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img3.jpg?raw=true)\n",
    "\n",
    "What do we mean by bandwidth available? Computers can transmit data to and from many different points of the Internet at the same time, but all those separate connections share the same bandwidth. Each connection will get a portion of the bandwidth, but the split isn't necessarily even. If one connection is transmitting a lot of data, there may be no bandwidth left for the other connections. When these traffic jams happen, the latency can increase a lot because packets might get held back until there's enough bandwidth to send them. You've probably experienced this already on your own computer. If you've ever run several applications using the same network at once, the overall connection speed may have seem slower. You can check out which processes are using the network connection by running a program like iftop. \n",
    "\n",
    "This shows how much data each active connection is sending over the network. You might also have noticed that the more users sharing the same network, the slower the data comes in. This is true for home connections and office connections alike. No matter how much bandwidth you have, it's a limited resource. So you'll need to be careful with how you share it among its users. If some applications are using so much bandwidth that others can't transmit anymore data, it's possible to restrict how much each connection takes by using **traffic shaping.** *This is a way of marking the data packets sent over the network with different priorities.* To avoid having huge chunks of data, use all the bandwidth. \n",
    "\n",
    "By prioritizing accordingly, processes that send and receive small packets can keep working fine, while processes that need the most bandwidth can use the rest. There's also a limit to how many network connections can be established on a single computer. This isn't usually a problem, but there could be bugs in the software that causes it to open way too many connections, or keep old connections open even if they're no longer in use. If this happens on a server, no new users will be able to connect to it until whatever is keeping those connections open closes them. Up next, we'll try our hand at solving another real-world example. This time, we'll be dealing with a memory leak and adjusting our program to make better use of our resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dealing with Memory Leaks\n",
    "\n",
    "There's a ton of reasons why an application may request a lot of memory. Sometimes, it's what we need for the program to complete it's task. Sometimes, it's caused by a part of the software misbehaving. First, let's trigger the misbehavior ourselves to see what this looks like. We'll use a terminal called **uxterm** for that.\n",
    "\n",
    "We've configured this terminal to have a really long scroll buffer. The scroll buffer is that nifty feature that lets us scroll up and see the things that we executed and their output. The contents of the buffer are kept in memory. So if we make it really long and we managed to fill it, will cause our computer to run out of memory. With normal use, it might take ages until it happens, but if we run a command that keeps generating a lot of output, we could manage to fill that buffer pretty quickly. Say we run a command like od-cx/dev/urandom. \n",
    "\n",
    "![img4](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img4.jpg?raw=true)\n",
    "\n",
    "This command will take the random numbers generated by the urandom device and show them as both characters and hexadecimal numbers. Since the urandom device keeps giving more and more random numbers, it will just keep going. Our command is filling up the scroll buffer, making a computer require more and more memory. In a different terminal, let's open top and check out what's going on.\n",
    "\n",
    "![img5](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img5.jpg?raw=true)\n",
    "\n",
    "Pressing \"Shift M\" we tell ton that we want to order the programs by how much memory they are using. We see that the percentage of memory used by uxterm is going up super quickly. Let's stop the process, it's filling up the buffer by pressing \"Control C\".\n",
    "\n",
    "With that, we stopped the command that was filling the buffer, but the terminal still has that memory allocated, storing all the lines in the scroll buffer. Let's look at the output of top in a bit more detail. There's a bunch of different columns with data about each process. The column labeled **RES** is the dynamic memory that's preserved for the specific process. The one labeled **SHR** is for memory that's shared across processes, and the one labeled **VIRT** lists all the virtual memory allocated for each process. This includes; process specific memory, shared memory, and other shared resources that are stored on disk but maps into the memory of the process. It's usually fine for a process to have a high value in the VIRT column. The one that usually indicates a problem is the **RES** column. Let's close the other terminal so that it releases all the memory that it reserved.\n",
    "\n",
    "![img6](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img6.jpg?raw=true)\n",
    "\n",
    "In this example, we saw what a program that keeps requesting more and more memory looks like. This was a super extreme example. Most memory leaks don't happen at the speed. It can usually take a long while until we notice that a program is taking more memory than it should, and it might be hard to tell the difference between memory that's actually needed and memory that's being wasted. But looking at the output of top and comparing it to what it used to be a while back is usually how any investigation into a memory leak starts. \n",
    "\n",
    "Let's look at a different example. We have a script that analyzes the frequency of words in web pages. This script works fine when it's just a few web pages, but if we try to give it all the Wikipedia contents, it starts using up all the memory. Let's run it first and see what happens.\n",
    "\n",
    "![img7](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img7.jpg?raw=true)\n",
    "\n",
    "This is running and it will take a long while to finish. It's processing a huge amount of articles after all. While this is running, let's look at the output of top in a different terminal and see what we find.\n",
    "\n",
    "![img8](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img8.jpg?raw=true)\n",
    "\n",
    "We see that there's a bunch of different content stats processes running. That's because our script is using the multiprocessing techniques that we saw in an earlier video to parallelize the processing of the information and get the results as fast as possible. It seems like these scripts are taking a lot of memory. So let's sort it out to see the details.\n",
    "\n",
    "We see that the memory used by one of the processes in particular keeps growing and growing. The application is processing a bunch of data and generating a dictionary with it. So it's expected that it will use some memory but not this much. This looks like the program is storing more than it should in memory. This program is pretty complex. So we could use the help of a memory profiler here to figure out what the problem is. Let's stop it now and use a profiler to figure out where our computer's memory is going. To do that, we'll need to use a simplified version of our code as profiling the memory of a multi-process application is extra hard, and instead of processing all the articles, we'll just handle a few so that we can check up the memory consumption quickly. Let's open our simplified script and have a look.\n",
    "\n",
    "We'll be using a module called memory profiler. This is one of the many different memory profilers available for Python.\n",
    "\n",
    "![img9](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img9.jpg?raw=true)\n",
    "\n",
    "We've added this app profile label before the main function definition to tell the profiler that we wanted to analyze the memory consumption of it. This type of label is called a **decorator** and *it's used in Python to add extra behavior to functions without having to modify the code.* In this case, the extra behavior is measuring the use of memory. The rest of the code is basically the same as the original one, it just uses a single process and is limited to 50 articles instead of the thousands of articles that the other script was going through.\n",
    "\n",
    "![img10](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img10.jpg?raw=true)\n",
    "\n",
    "We're running the script with the memory profiler enabled. This is just reading through 50 articles but it takes a bunch of time because all that memory profiling makes our script slower. \n",
    "\n",
    "![img11](https://github.com/Brian-E-Nguyen/Google-IT-Automation-with-Python/blob/4-Troubleshooting-and-Debugging-Techniques/4-Troubleshooting-and-Debugging-Techniques/Week-4-Managing-Resources/img/img11.jpg?raw=true)\n",
    "\n",
    "Once the program finishes, the memory profiler gives us information about which lines are adding or removing data from the memory used by the program. The first column shows us the amount of memory required when each line gets executed. The second one shows the increase in memory for each specific line. We see here that after going through 50 articles, the program already took 130 megabytes, no wonder we ran out of memory when we were trying to process all the articles. We can see that the variables that require the most memory are article and text, with about four and of three megabytes respectively. Those are the articles we're processing, and it's fine for them to take space while we're counting the words in the article. But once were done processing one article, we shouldn't keep that memory around. Can you spot the problem?\n",
    "\n",
    "Right at the end, the code is storing the article to keep a reference to it, but it's storing the whole article. If we want to keep a reference to all the articles that include a word, we could store the titles or the index entries, definitely not the whole contents. There's a ton more to say about memory management and memory profiling that we don't have time to cover here. In the next reading, we've gathered a bunch of interesting links to information about managing scarce resources. After that, there's another practice quiz for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. More About Managing Resources\n",
    "\n",
    "Check out the following links for more information:\n",
    "\n",
    "- https://realpython.com/python-concurrency/\n",
    "- https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32\n",
    "- https://www.pluralsight.com/blog/tutorials/how-to-profile-memory-usage-in-python\n",
    "- https://www.linuxjournal.com/content/troubleshooting-network-problems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
